import streamlit as st
import torch
from transformers import DistilBertTokenizer, DistilBertForSequenceClassification
# BertTokenizer, BertForSequenceClassification, 
# Load the tokenizer and model
# tokenizer = BertTokenizer.from_pretrained('bert_model')
# model = BertForSequenceClassification.from_pretrained('bert_model')
tokenizer = DistilBertTokenizer.from_pretrained('distilbert_model')
model = DistilBertForSequenceClassification.from_pretrained('distilbert_model')

# Move the model to the appropriate device (GPU or CPU)
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# Ensure the model is in evaluation mode
model.eval()

# Define the prediction function
def predict(input_text):
    # Tokenize the input text
    encoding = tokenizer.encode_plus(
        input_text,
        add_special_tokens=True,
        max_length=256,
        return_token_type_ids=False,
        padding='max_length',
        truncation=True,
        return_attention_mask=True,
        return_tensors='pt',
    )
    
    # Move the tensors to the appropriate device
    input_ids = encoding['input_ids'].to(device)
    attention_mask = encoding['attention_mask'].to(device)
    
    # Make the prediction
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    
    # Get the predicted class
    logits = outputs.logits
    prediction = torch.argmax(logits, dim=1).item()
    
    # Interpret the prediction
    if prediction == 1:
        result = "The content is written by AI."
    else:
        result = "The content is written by a human."
    
    return result

# Streamlit interface
st.title("AI vs Human Text Distill BERT Detector")
st.write("Enter a text below to check whether it was generated by AI or written by a human.")

input_text = st.text_area("Input Text")

if st.button("Predict"):
    result = predict(input_text)
    st.write(result)
